{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "_(by Standford University)_\n",
    "\n",
    "**WEEK 1**\n",
    "\n",
    "Course of introduction to machine learning offered by Standford University on [Coursera.org](https://www.coursera.org/learn/machine-learning). These are **notes** and **comments** based on lectures and assignments.\n",
    "\n",
    "The IPython kernel of choice is *Octave* since many exercises and assignments have been devised for that language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Terminology\n",
    "\n",
    "- Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed (A. Samuel, 1959);\n",
    "- A computer program is said to learn from experience _E_ with respect to some task _T_ and some performance measure _P_, if its performance on _T_, as measured by _P_, improves with _E_. (T. Mitchell, 1998).\n",
    "\n",
    "_e.g.: a spam recognition program in an e-mail client has spam/non-spam classification as task T, watching the user labelling e-mails as experience E and the no. of correctly classified e-mails as performance P._\n",
    "\n",
    "_e.g.: a chess playing program has the task T of playing chess, through the experience E gained by playing many games and the performance P given by the probability of winning the current game._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Algorithms\n",
    "\n",
    "### Supervised Machine Learning\n",
    "\n",
    "- the \"right answers\" are given to the algorithm\n",
    "- we ask the algorithm to produce more \"right answers\"\n",
    "\n",
    "_e.g.: a regression problem such as housing price prediction given some input data (size, position, etc.)._\n",
    "\n",
    "_e.g.: a classification problem such as the prediction of malignant vs. benign tumors using medical data (tumor size, age of the patient, etc.)._\n",
    "\n",
    "Algorithms can also deal with an infinite no. of features describing the output labels (Support Vector Machines) using a mathematical trick.\n",
    "\n",
    "### Unsupervised Machine Learning\n",
    "\n",
    "- data are not labelled\n",
    "- we ask the algorithm to find some structure to the data\n",
    "\n",
    "_e.g.: Google News groups similar news stories into topics and then shows them to the user grouped by topic._\n",
    "\n",
    "_e.g.: using genome information of individuals, we can find clusters of people based on the representation of some genes._\n",
    "\n",
    "_e.g.: using marketing information we can group customers into segments and offer them better suited offers. We do not know in advance their preferences._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Cost Function - Introduction\n",
    "\n",
    "### Vocabulary\n",
    "\n",
    "- input data are usually called _features_;\n",
    "- output data can usually be referred to as _targets_ or _labels_;\n",
    "- the function that learns the task is usually called _hypothesis_ (and indicated as _h_).\n",
    "\n",
    "### A First Example: Linear Regression\n",
    "\n",
    "- predict continuous output;\n",
    "- use a univariate/linear model for regression: $h_{\\theta}(x) = \\theta_0 + \\theta_1 x$.\n",
    "\n",
    "#### The Cost Function\n",
    "\n",
    "- $\\theta_0$ and $\\theta_1$ are the **parameters** of the hypothesis;\n",
    "- how can we choose the parameters in order to better approximate the input data? We solve a minimisation problem to minimize the **cost function** $J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum\\limits_{i = 1}^m (h^{(i)}_{\\theta}(x) - y^{(i)})^2$ (_squared error cost function_, usually the best option for most regression problems);\n",
    "- cost functions are usually minimised using the **gradient descent** method. Algorithmically, this means to start with a choice of $\\theta$ and change them in order to find the minimum of $J(\\theta)$.\n",
    "\n",
    "#### Gradient Descent Method\n",
    "\n",
    "- from the technical point of view, the gradient descent is: $\\theta_j' = \\theta_j - \\alpha \\nabla J(\\theta)$ to be repeated until convergence;\n",
    "- $\\alpha$ is called **learning rate** and controls the width of the step towards the minimum (must be $\\ge 0$);\n",
    "- all parameters $\\theta_j$ must be updated simultaneously;\n",
    "- if $\\alpha$ is too small, the gradient descent can be very slow;\n",
    "- if $\\alpha$ is too large, the gradient descent can overshoot the real minimum and diverge;\n",
    "- as we reach the minimum, $\\alpha$ does not need to decrease since the derivative of $J$ is already smaller;\n",
    "- a gradient descent which uses the full set of input features is called **batch gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra in Octave/MatLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v =\n",
      "\n",
      "   1\n",
      "   2\n",
      "   3\n",
      "\n",
      "M =\n",
      "\n",
      "   1   2   3   4\n",
      "   5   6   7   8\n",
      "   9   0   0   0\n",
      "\n",
      "dim_v =\n",
      "\n",
      "   3   1\n",
      "\n",
      "dim_M =\n",
      "\n",
      "   3   4\n",
      "\n",
      "rowv =  3\n",
      "colv =  1\n",
      "rowM =  3\n",
      "colM =  4\n",
      "M_31 =  9\n",
      "v_1 =  1\n"
     ]
    }
   ],
   "source": [
    "% create a column vector\n",
    "v = [ 1;\n",
    "      2;\n",
    "      3\n",
    "    ]\n",
    "\n",
    "% create a matrix (use , to separate entries in a row and ; to separate columns)\n",
    "M = [ 1, 2, 3, 4;\n",
    "      5, 6, 7, 8;\n",
    "      9, 0, 0, 0\n",
    "    ]\n",
    "    \n",
    "% get the dimensions of v and M\n",
    "dim_v          = size(v) % method 1: store as [ rows, columns ]\n",
    "dim_M          = size(M)\n",
    "[ rowv, colv ] = size(v) % method 2: store rowvs and columns separately\n",
    "[ rowM, colM ] = size(M)\n",
    "\n",
    "% refer to a specific element of a vector or matrix (enumeration starts from 1, not 0)\n",
    "M_31 = M(3,1)\n",
    "v_1  = v(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s =  3\n",
      "w =\n",
      "\n",
      "   3\n",
      "   6\n",
      "   9\n",
      "\n",
      "N =\n",
      "\n",
      "    3    6    9   12\n",
      "   15   18   21   24\n",
      "   27    0    0    0\n",
      "\n",
      "z =\n",
      "\n",
      "   0.33333\n",
      "   0.66667\n",
      "   1.00000\n",
      "\n",
      "P =\n",
      "\n",
      "   0.33333   0.66667   1.00000   1.33333\n",
      "   1.66667   2.00000   2.33333   2.66667\n",
      "   3.00000   0.00000   0.00000   0.00000\n",
      "\n",
      "ans =\n",
      "\n",
      "    3.6667\n",
      "    7.3333\n",
      "   11.0000\n",
      "\n",
      "ans =\n",
      "\n",
      "    3.66667    7.33333   11.00000   14.66667\n",
      "   18.33333   22.00000   25.66667   29.33333\n",
      "   33.00000    0.00000    0.00000    0.00000\n",
      "\n",
      "ans =\n",
      "\n",
      "   4\n",
      "   5\n",
      "   6\n",
      "\n",
      "ans =\n",
      "\n",
      "    4    5    6    7\n",
      "    8    9   10   11\n",
      "   12    3    3    3\n",
      "\n",
      "ans =\n",
      "\n",
      "   38\n",
      "   14\n",
      "   17\n",
      "   20\n",
      "\n",
      "ans =\n",
      "\n",
      "   321    96   114   132\n",
      "    96   120   144   168\n",
      "   114   144   174   204\n",
      "   132   168   204   240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% initialise a scalar\n",
    "s = 3\n",
    "\n",
    "% multiply a vector or matrix by a scalar\n",
    "w = s * v\n",
    "N = s * M\n",
    "\n",
    "% divide a vector or matrix by a scalar\n",
    "z = v / s\n",
    "P = M / s\n",
    "\n",
    "% add and subtract two vectors or matrices\n",
    "v + w - z\n",
    "N + M - P\n",
    "\n",
    "% N.B.: we can add a scalar to a matrix or vector (as if s = s * I)\n",
    "v + s\n",
    "M + s\n",
    "\n",
    "% compute matrix multiplication\n",
    "transpose(M) * v\n",
    "transpose(M) * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =\n",
      "\n",
      "     1   123\n",
      "     1   432\n",
      "     1   453\n",
      "\n",
      "C =\n",
      "\n",
      "  -0.20000   0.10000   0.50000\n",
      "   0.40000   0.20000  -0.10000\n",
      "\n",
      "Y =\n",
      "\n",
      "    49.000    24.700   -11.800\n",
      "   172.600    86.500   -42.700\n",
      "   181.000    90.700   -44.800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% let h1(x) = -0.2 + 0.4 * x, h2(x) = 0.1 + 0.2 * x, h3(x) = 0.5 - 0.1 * x, compute the predictions given some input x\n",
    "x = [ 123;\n",
    "      432;\n",
    "      453\n",
    "    ];\n",
    "    \n",
    "X = [ ones(size(x)), x]\n",
    "C = [ -0.2, 0.1, 0.5; 0.4, 0.2, -0.1 ]\n",
    "Y = X * C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "\n",
      "   0.0073865   0.5150664   0.5437590\n",
      "   0.3176411   0.4142731   0.7174166\n",
      "   0.6669764   0.6309237   0.5507306\n",
      "\n",
      "trA =  0.97239\n",
      "detA =  0.11343\n",
      "invA =\n",
      "\n",
      "  -1.97912   0.52376   1.27179\n",
      "   2.67635  -3.16161   1.47605\n",
      "  -0.66919   2.98767  -1.41544\n",
      "\n",
      "AT =\n",
      "\n",
      "   0.0073865   0.3176411   0.6669764\n",
      "   0.5150664   0.4142731   0.6309237\n",
      "   0.5437590   0.7174166   0.5507306\n",
      "\n",
      "ans =\n",
      "\n",
      "  1  1  1\n",
      "  1  1  1\n",
      "  1  1  1\n",
      "\n",
      "I =\n",
      "\n",
      "Diagonal Matrix\n",
      "\n",
      "   1   0   0\n",
      "   0   1   0\n",
      "   0   0   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% special matrices\n",
    "pkg load statistics\n",
    "\n",
    "A    = unifrnd(0, 1, [3,3])\n",
    "trA  = trace(A)\n",
    "detA = det(A)\n",
    "invA = pinv(A) % use the pseudoinverse for simplicity and speed (it return the inverse for non singular square matrices)\n",
    "AT   = A'\n",
    "\n",
    "A'   == transpose(A)\n",
    "\n",
    "I = eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "5.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
